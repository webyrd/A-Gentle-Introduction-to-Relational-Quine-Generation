Think about how I'd do this for a web-based, Google Hangout tutorial
series.  One approach (very 311-like):

Intro to Scheme
Quasiquote
Simple recursive functions
  factorial
  fib
    naive vs smart
    memoing/tabling
  length
  member
  rember
  append
  deep recursion
Lexical scope
Pattern matching/pmatch
-----------------------
core miniKanren
simple recursive relations in miniKanren (appendo, rembero/surpriseo, etc)
=/=
rembero revisited
symbolo/numbero
Oleg numbers
CLP(fd)
absento
-----------------------
Environments
Different Ways to Represent Environments: higher-order, DS
CBV Lambda Calculus
  alpha-equivalence/alpha-conversion
  eta
  CBV/CB name/CB need
Higher-order 3x5 card interpreter
Extend to handle factorial
  numbers
  zero?
  sub1
  *
  if
RI
Defunctionalization/DS version of interpreter (procedures/environments)
lexical vs dynamic scope
adding quote/list/cons/car/cdr/etc
-----------------------
environment lookup in miniKanren
DS CBV LC interpeter
adding quote
adding cons/car/cdr/null?
(I love you)
fun with quines
adding if
running append in the interpreter
adding list
adding numbers
factorial
-----------------------
set! and store-passing style
continuations and cps
-----------------------
adding set! in miniKanren
CPS--seems like a troublemaker!!
----------------------
call-by-name LC
  capture-avoiding substition
----------------------
nominal logic programming
----------------------
combinatory logic
----------------------
CL in miniKanren
eigen
fixpoint combinator synthesis
----------------------
open problems



[Another possible way to write the book, that I have thought about
before and should seriously consider: teach C311 through miniKanren.
Start with the miniKanren language, trivial programs, simple recursive
programs like append and member, introduce necessary constraints, then
introduce concepts like free and bound variables, lexical scope,
shadowing, etc.  Then move to interpreters.

This would avoid some of the issues with background knowledge, and
would make everything much more self contained.  The tradeoff, I
think, is that these ideas may be harder to first understand in the
context of miniKanren/relational programming than they are in Scheme,
for example.  Also, miniKanren is always embedded in a host language,
so I'd still want to teach some Scheme.  And, finally, if we are
exploring and interpreting a programming language, like Scheme, seems
important to have a good grasp of Scheme first.  Although, I could
start more basic, with LC, and maybe even CL before that, and then
build towards Scheme that way.  Hmmm--that sounds like an interesting
approach.  Although I'm not sure if I'll be able to pull off
Call-by-name LC without nominal logic programming, which seems like a
lot to introduce at the beginning.

What I *could* do is use a modified version of this approach, assuming
that the reader already knows how to write recursive Scheme programs.
So, basically the second or third week of C311, up through
store-passing interpreters.

Or...I could use a more Chomskyesh approach.  Assume the reader knows
Scheme.  Show how to encode DFAs, NFAs, PDAs, linear bounded automata,
etc, up to Turing machines and interpreters.  All of this stuff is fun
and cool.]



[lots to learn from append: appendo/reordering/divergence/swappendo
and append within the relational interpreter]



[need to be careful to fight against scope creep!  maybe...]

[An explicit goal: after reading the book, the reader should be able
to pick up a paper on miniKanren, and understand/implement/experiment
with the ideas and code in the paper.]

[who exactly is my audience?  Am I going to try to teach someone new
to both functional programming and logic programming enough to do
research in mk?  Seems like a tall order.]

[could work backwards: write "Volume III" first, which would assume
that the reader knew about Scheme and functional programming ("Volume
I", equivalent to C211/Scheme and the Art/HtDP/whatever), and also
about program transformations and interpreters ("Volume
II"--equivalent to EOPL, or first half of C311/B521))]

[Should I strip down this material to a truly minimal version?  For
example, do I really need to get into details of lambda calculus,
capture-avoiding substitution, and call-by-need in order to show the
miniKanren big-step interpreter?  Not necessarily.  Of course, leaving
out those ideas removes much of the context and space to explore.  I
need to think more about this.]

[One (test) audience for a "Volume III" would be IU students who have
finished the first half of C311/B521.  Or students at Utah who have
taken an interpreters course, although I'm not sure they learn about
defunctionalization/etc.]




[what about the implementation of mk?  seems like lots of people want
to understand the implementation, which is both fun to understand, and
might make the behavior of the programs easier to understand.  Could
I *start* with the implementation of micro/mini-on-micro, maybe after
a brief intro to relational programming?  Then move on to more
advanced mk programming?]




I like this approach due to the symmetry between parts:

PART I & PART IV
PART II & PART V
PART III & PART VI

Also, this structure allows people who know Scheme/program
transformations/interpreters to skip intro sections of the book.

Keep thinking about how I teach people these ideas in person.

** Intro
* PART I: SCHEME [the parts we'll need; keep as concrete and programmy as possible]
  [this order of presentation seems friendly to newbies]

  [could probably use this presentation order for the Hangouts]

  [an intro to Scheme, but definitely from the perspective of an
  implementer and user of pure logic programming languages; for example,
  we could completely leave out I/O and effects without significantly
  altering the rest of the book]
** Scheme Fundamentals
*** the REPL
*** numbers
*** arithmetic 
    [show big numbers and all of that!!]
*** expressions vs values
*** quote & symbols 
    [point out the beauty/power of symbolic data]
*** pairs and lists 
    [point out that nested lists represent tree structures]
**** box & pointers
**** inductive definition of a proper list
*** boolean constants
*** conditionals
*** Scheme's notion of truth
*** equality predicates
*** define 
    [define gives a name to a value]
*** variables
*** type predicates
*** lambda & procedures
*** procedure application
*** S-expressions 
    [point out that in Scheme parens are always significant]
*** Scheme's evaluation rules 
    [call-by-value & special forms]
*** redefining Scheme's built-in procedures 
    [point out that procedure application
    can't be redefined, and numbers can't be redefined, although the arithmetic 
    procedures can be redefined; is redefinition a good thing?  scares lots of 
    programmers; Joe A: laguage tradeoffs, does the language design hang together, 
    in light of those tradeoffs?]
*** recursion
** Writing Recursive Procedures
   [writing simple recursive programs & thinking recursively]
*** the wishful thinking approach to thinking recursively
*** length
*** member
*** rember
*** append
*** factorial
*** fib
*** natural (direct-style) recursion vs tail recursion
**** visualizing recursion
*** mutual recursion
**** even & odd
** Other Useful Aspects of Scheme
*** quasiquote & unquote
*** let
*** letrec
*** varargs
*** apply
*** eval
*** input and output 
    [tells the reader something about the perspective of
    this book that I initially forgot to include input/output in the
    intro to programming in Scheme]
*** set!
*** set-car! & set-cdr!
*** vectors
*** continuations & call/cc
*** syntactic extension
**** syntax-rules/syntax-case/syntax-parse (Racket)
**** examples
***** pattern matching (pmatch/match) 
      [we'll be using pattern matching in our Scheme interpreter, and
      a similar pattern-matching syntax in miniKanren]
***** embedded domain-specific languages
* PART II: TRANSFORMING SCHEME PROGRAMS [just the transformations useful for doing (or understanstanding) transformations for our interpreters]
  [many people think of program transformations as something done by a
  computer program; they can also be performed by hand, either because a
  program might need human guidance (as in making code RI, for example),
  or just because transforming by hand gives us an unprecedented level
  of control and insight]
** Variable Renaming and eta-Expansion/Contraction
*** Consistent Renaming of Variables
    [a.k.a. alpha conversion]
**** based on the notion of alpha-equivalence from lambda-calculus 
     [as we'll see in Part III]
**** must respect lexical scope & avoid variable capture 
     [give examples showing the problems]

     [point out nominal unification in margin note]
*** eta-Expansion/Contraction
    [add1 vs. (lambda (x) (add1 x)) is probably the easiest example to keep in mind]
**** can change divergence behavior 
     [for example, Z vs Y combinator]

     [give examples]
**** careful to avoid variable capture 
     [give example]
**** careful with the number of arguments when playing with variadic procedures
     [such as +]
***** for variadic functions, can use varargs
      [((lambda args (apply + args)) 3 4 5) => 12]
** Contintuation-Passing Style and A-Normal Form
*** Continuation-Passing Style
    [tie to a normal-form]

    [present before RI & defunctionalization, so we'll have examples
    to practice on before we get to the interpreter; is there a better
    way to do this?  RI/defunctionalize something else?  I could do
    environment lookup/extension, for example, but this seems
    unmotivated at this point in the book.]
**** gateway drug of program transformations
     [because of the properties of the resulting code]
**** serious vs simple expressions
**** show aps as part of the description: factorial in direct-style, aps, and cps, with the tradeoffs
***** stack vs heap usage
***** tracing of program execution
**** formal rules for cps
**** properties of cps'd code
***** lambda expressions take an extra argument
***** all series calls are in tail position
***** all arguments to calls are simple
***** fixes order of evaluation
**** can CPS code multiple times
     [margin note--CPSing miniKanren relations in a way that preserves
     "running backwards" efficiently is still an open problem]

     [execise: write a CPSer in Scheme]
*** A-Normal Form
    [essence of compiling with continuations]
    
    [gives us similar properties for the resulting code, but without
    the overhead of explicit continuations (can all the C311/521
    program transformations be based on ANF rather than CPS?)]

    [real reason to look a ANF, from the perspective of this book:
    we'll be using a similar transformation when we start translating
    Scheme code to miniKanren]

    [which examples to use? factorial, append]
**** formal rules for anf
**** properties of code in ANF
** Representation-independence and Defunctionalization
*** Representation-independence
    [careful with terminology: RI *wrt*
    continuations/procedures/environments/whatever.]
**** distinction between higher-order vs. first-order representations
     [terinology: DS = FO representation; HO rep]
***** higher-order rep
***** DS representations tagged lists vs a-lists vs. other (for example, records)
      [when we go to mk, we'll need to stick to first-order
      representations that we can compare with Scheme's equal?, since
      miniKanren uses first-order unification, which is a syntactic
      equality constraint]

      [defunctionalization in the next sub-section will allow us to
      mechanically transform higher-order representations into
      first-order representations, going through an intermediate stage
      of making the code RI wrt whatever we want to defunctionalize]

      [demonstrate on continuations in CPSed code; will demonstrate
      for environments and procedures in the interpreter]
*** Defunctionalization
    [especially useful when porting code to a spartan host like C, for
    debugging (can print the representation of a procedure, for
    example), serialization, or when using pattern-matching (or
    unification!)]

    [personal usage: often I find difficult or complex ideas easiest
    to express using HO representation. I might then defunctionalize
    the code for debugging/visualization/serialization/whatever.  I
    might switch between representations multiple times during the
    development of a complex program. (In miniKanren, though, I almost
    always stick to DS rep)]

    [demonstrate on continuations in CPSed code; will demonstrate for
    environments and procedures in the interpreter]
* PART III: WRITING INTERPRETERS IN SCHEME
** lambda-calculus
*** syntax
*** alpha-conversion 
    [we've seen this before in Part II]
*** beta reduction
**** substitution
***** naive vs capture-avoidance
*** eta reduction/expansion
*** LC is Turing-complete 
    [a bit ironic to say it that way]
*** undecidability of term equivalence under beta-reduction
*** confluence
*** combinators & combinatory logic
**** S,K,I combinators
**** bases
***** single-combinator bases 
      [point to Okasaki paper]
**** Y combinator
*** call-by-name vs. call-by-need vs. call-by-value
**** Z combinator
*** aside: Church encoding
** a big-step direct-style environment-passing interpreter for the CBV LC
*** context
**** big-step interpreter vs. small-step reducer 
     [reference EOPL and PLT Redex books]
**** environments vs substitution
*** higher-order version
*** first order version
** adding list and quote
*** 99 ways to say (I love you), inspired by Matt's blog post
*** can run quines
** adding pair operators
*** more ways to say (I love you)
** adding booleans
   [point out this isn't really necessary: could use if0, for example]
** adding 'if'
*** 'append' using Y combinator
** adding numbers
** adding sub1 and *
*** factorial
** adding set! using store-passing style
** adding call/cc using cps
** Exercise: add other primitive functions and forms to the interpreter
** Exercise: add built-in procedures to the environment rather than hard-coding them in the interpreter
   [I should play around with this myself, and see how this works in
   miniKanren-land.  Is this approach even possible for a small-step
   reducer?]
* PART IV: MINIKANREN
** the core language
** append & appendo
*** reordering of clauses and goals
**** swappendo works because of miniKanren's complete search
     [would diverge in Prolog with DFS, for example, if the first list
     and the output argument were fresh, since there would be nothing
     to cut off the recursion; in fact, if the first and last args
     aren't fresh, but aren't length instantiated, could still
     diverge! (double check that I'm right about divergence with this
     specific case--would be nice to have a DFS miniKanren for playing
     around with these examples!)]
**** reordering the conjuncts isn't as forgiving!  
     [For best divergence behavior, simple goals should come before
     serious goals]

     [this doesn't necessarily result in the fastest behavior for any
     given mode, however!]
** member/rember/surpriseo
   [could call this section "Too many secrets", and have a list
   containing (or generated to contain) multiple occurrences of the
   symbol 'secret]

   [different from 'append' in that we need to actually look at the
   values of the elements, to see if an element of the list is indeed
   the element we are looking for]

   [can easily express that 'x' and an element of 'ls' are
   syntactically equal, using ==; how do we express that two terms are
   not equal???  Punt for now.]

   [Shows damage of cond/else to declarativeness.  Dijkstra guard!]
** =/= extension
   [need to be careful to describe exactly what the constraint means,
   and give examples showing the tricky corner cases]

   [very limited form of negation; for example, can't express
   'not-pair']
** rembero reconsidered
   [no many surprises]
** symbolo & numbero
** absento
* PART V: TRANSFORMING SCHEME TO MINIKANREN
** an example
** the steps
** defunctionalization 
   [especially important because miniKanren's unification is first-order]
** cps is problematic
   [one of several ways to "break the wires"]

   [probably keep this section as short as possible, and just point to
   the relevant Open Problems section]

   [not sure this is the right way/place to introduce the problem,
   since breaking the wires via CPS appears to be just one example of
   a larger class of problems; for example, the transitive closure of
   small-step calls in a small-step interpreter also seems to break
   the wires.  Maybe 'breaking the wires' needs to be a section, and
   need to have a general discussion of the problem, and of our
   efforts to remediate the problem]
* PART VI: WRITING INTERPRETERS IN MINIKANREN
  [do I want to show: CL reducer; Call-by-name LC reducer in nominal
  logic; small-step reducer?]
** big-step CBV lambda calculus interpreter
** adding list and quote
*** (I love you)
*** quines, twines, and thrines
** adding pair operations
** adding 'if'
*** 'append' using Y combinator; running 'append' backwards
** adding set! using store-passing style
* PART VII: Open Problems
** Reconnecting Broken Wires
   [as I said above, this problem is more about "breaking the wires"
   than about CPS; this is also an issue with the transitive closure
   of the step operator of a small-step interpeter (as opposed to the
   equivalent termination/pruning behavior of an equivalent big-step
   interpreter)]
